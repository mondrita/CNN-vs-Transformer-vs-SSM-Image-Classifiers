{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10157629,"sourceType":"datasetVersion","datasetId":6271724},{"sourceId":10157971,"sourceType":"datasetVersion","datasetId":6271993},{"sourceId":10170011,"sourceType":"datasetVersion","datasetId":6280848}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,random_split\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n\nfrom torchvision import transforms, datasets\n\nfrom sklearn.metrics import (\n    roc_curve,\n    auc,\n    confusion_matrix,\n    precision_score,\n    recall_score,\n    f1_score\n)\nfrom sklearn.utils import class_weight\n\nfrom PIL import Image\nfrom torch.optim.lr_scheduler import StepLR\nimport random\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:29:16.577482Z","iopub.execute_input":"2024-12-23T12:29:16.577723Z","iopub.status.idle":"2024-12-23T12:29:25.678128Z","shell.execute_reply.started":"2024-12-23T12:29:16.577691Z","shell.execute_reply":"2024-12-23T12:29:25.677228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 42\ntorch.manual_seed(seed)           \nrandom.seed(seed)                  \nnp.random.seed(seed)               \ntorch.cuda.manual_seed(seed)       \ntorch.backends.cudnn.deterministic = True  \ntorch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:29:25.679037Z","iopub.execute_input":"2024-12-23T12:29:25.679384Z","iopub.status.idle":"2024-12-23T12:29:25.694952Z","shell.execute_reply.started":"2024-12-23T12:29:25.679356Z","shell.execute_reply":"2024-12-23T12:29:25.694105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"train_data_path = '/kaggle/input/flame-ds/Training/Training'\ntest_data_path = '/kaggle/input/flame-ds/Test/Test'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:29:25.695775Z","iopub.execute_input":"2024-12-23T12:29:25.696065Z","iopub.status.idle":"2024-12-23T12:29:25.699147Z","shell.execute_reply.started":"2024-12-23T12:29:25.696036Z","shell.execute_reply":"2024-12-23T12:29:25.698454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\n\n# Load dataset\ntrain_dataset = datasets.ImageFolder(root=train_data_path)\n\n# Print class-to-index mapping\nprint(\"Class-to-Index Mapping:\", train_dataset.class_to_idx)\n\n# Get counts of each label\nlabel_counts = Counter([sample[1] for sample in train_dataset.samples])\n\n# Print counts for each label\nprint(\"Label Counts:\")\nfor label, count in label_counts.items():\n    class_name = list(train_dataset.class_to_idx.keys())[list(train_dataset.class_to_idx.values()).index(label)]\n    print(f\"{class_name}: {count} images\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:29:25.700687Z","iopub.execute_input":"2024-12-23T12:29:25.700888Z","iopub.status.idle":"2024-12-23T12:30:01.956082Z","shell.execute_reply.started":"2024-12-23T12:29:25.700871Z","shell.execute_reply":"2024-12-23T12:30:01.955340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize\n    transforms.RandomHorizontalFlip(p=0.5),  # Horizontal flip\n    transforms.RandomVerticalFlip(p=0.5),  # Vertical flip\n    transforms.RandomRotation(degrees=10),  # Rotation\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Color jitter\n    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.5)),  # Gaussian noise\n    transforms.ToTensor(),  # Convert to Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize\n    transforms.ToTensor(),  # Convert to Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:01.957358Z","iopub.execute_input":"2024-12-23T12:30:01.957578Z","iopub.status.idle":"2024-12-23T12:30:01.963456Z","shell.execute_reply.started":"2024-12-23T12:30:01.957559Z","shell.execute_reply":"2024-12-23T12:30:01.962562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\n# Load datasets (without transformations initially)\ntrain_dataset = datasets.ImageFolder(root=train_data_path)\ntest_dataset = datasets.ImageFolder(root=test_data_path, transform=test_transforms)\n\n# Oversampling to balance classes\nindices = list(range(len(train_dataset)))\ntargets = [sample[1] for sample in train_dataset.samples]  # Labels for each sample\n\nros = RandomOverSampler(sampling_strategy=0.8, random_state=42)\nresampled_indices, resampled_targets = ros.fit_resample(np.array(indices).reshape(-1, 1), targets)\nresampled_indices = resampled_indices.flatten()\n\n# Create oversampled subset\ntrain_subset = Subset(train_dataset, resampled_indices)\ntrain_subset.dataset.transform = train_transforms  # Apply augmentation to the subset\n\n# Stratified train-validation split (80-20)\nfrom sklearn.model_selection import train_test_split\n\ntrain_indices, val_indices = train_test_split(\n    range(len(train_subset)),\n    test_size=0.2,\n    stratify=resampled_targets,\n    random_state=42\n)\n\ntrain_split = Subset(train_subset, train_indices)\nval_split = Subset(train_subset, val_indices)\n\n# Apply test transforms to validation subset\nval_split.dataset.transform = test_transforms\n\n# Data loaders\ntrain_loader = DataLoader(train_split, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_split, batch_size=32, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# Print dataset sizes\nprint(f\"Training Set Size: {len(train_split)} images\")\nprint(f\"Validation Set Size: {len(val_split)} images\")\nprint(f\"Testing Set Size: {len(test_dataset)} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:01.964357Z","iopub.execute_input":"2024-12-23T12:30:01.964592Z","iopub.status.idle":"2024-12-23T12:30:34.190181Z","shell.execute_reply.started":"2024-12-23T12:30:01.964562Z","shell.execute_reply":"2024-12-23T12:30:34.189458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\n\n# Directly count labels for train_split and val_split using resampled_targets\ndef subset_label_counts(subset_indices, resampled_targets):\n    # Map the subset indices to resampled_targets\n    labels = [resampled_targets[i] for i in subset_indices]\n    return Counter(labels)\n\n# Count labels for train and validation splits\ntrain_label_counts = subset_label_counts(train_indices, resampled_targets)\nval_label_counts = subset_label_counts(val_indices, resampled_targets)\n\nprint(\"\\nTraining Label Distribution:\")\nfor label, count in sorted(train_label_counts.items()):\n    print(f\"Class {label}: {count} samples\")\n\nprint(\"\\nValidation Label Distribution:\")\nfor label, count in sorted(val_label_counts.items()):\n    print(f\"Class {label}: {count} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:34.191102Z","iopub.execute_input":"2024-12-23T12:30:34.191578Z","iopub.status.idle":"2024-12-23T12:30:34.202511Z","shell.execute_reply.started":"2024-12-23T12:30:34.191551Z","shell.execute_reply":"2024-12-23T12:30:34.201782Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load Model**","metadata":{}},{"cell_type":"code","source":"from timm import create_model\n\n# Load a pretrained Xception model\nmodel = create_model('xception', pretrained=True)\nnum_features = model.fc.in_features  # The fully connected layer in Xception is `fc`\nmodel.fc = nn.Linear(num_features, 2)  # 2 for binary classification\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:34.203183Z","iopub.execute_input":"2024-12-23T12:30:34.203496Z","iopub.status.idle":"2024-12-23T12:30:39.566164Z","shell.execute_reply.started":"2024-12-23T12:30:34.203474Z","shell.execute_reply":"2024-12-23T12:30:39.565476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1, verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:39.566910Z","iopub.execute_input":"2024-12-23T12:30:39.567123Z","iopub.status.idle":"2024-12-23T12:30:39.575650Z","shell.execute_reply.started":"2024-12-23T12:30:39.567105Z","shell.execute_reply":"2024-12-23T12:30:39.574895Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Train**","metadata":{}},{"cell_type":"code","source":"# Early Stopping Class\nclass EarlyStopping:\n    def __init__(self, patience=5, delta=0.0):\n        self.patience = patience\n        self.delta = delta\n        self.best_loss = float('inf')\n        self.counter = 0\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss - self.delta:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                print(\"Early stopping triggered!\")\n                self.early_stop = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:39.576381Z","iopub.execute_input":"2024-12-23T12:30:39.576608Z","iopub.status.idle":"2024-12-23T12:30:39.590494Z","shell.execute_reply.started":"2024-12-23T12:30:39.576587Z","shell.execute_reply":"2024-12-23T12:30:39.589894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport time\nfrom tqdm import tqdm\n\ndef train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, criterion, device, patience=5, num_epochs=50):\n    early_stopping = EarlyStopping(patience=patience)\n    model.to(device)\n\n    # Lists to track metrics\n    train_losses, val_losses, train_accuracies, val_accuracies, learning_rates = [], [], [], [], []\n    gpu_usage, fps = [], []\n\n    for epoch in range(num_epochs):\n        # Fetch and print the current learning rate\n        current_lr = optimizer.param_groups[0]['lr']\n        learning_rates.append(current_lr)  # Track learning rate\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Learning Rate: {current_lr:.6f}\")\n\n        model.train()\n        train_loss, correct, total = 0.0, 0, 0\n\n        # GPU memory tracking\n        start_time = time.time()\n        for images, labels in tqdm(train_loader, desc=\"Training Batches\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images)\n\n            # Check for logits attribute (e.g., in DeiT models)\n            if hasattr(outputs, 'logits'):\n                outputs = outputs.logits\n\n            # Compute loss and backpropagate\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        # Monitor GPU memory usage\n        gpu_allocated = torch.cuda.memory_allocated(device) / (1024 ** 3)  # Convert to GB\n        gpu_reserved = torch.cuda.memory_reserved(device) / (1024 ** 3)   # Convert to GB\n        gpu_usage.append((gpu_allocated, gpu_reserved))\n\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100. * correct / total\n        train_losses.append(epoch_loss)  # Track training loss\n        train_accuracies.append(epoch_acc)  # Track training accuracy\n\n        # Measure FPS\n        end_time = time.time()\n        fps_epoch = len(train_loader.dataset) / (end_time - start_time)\n        fps.append(fps_epoch)\n\n        print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.2f}%, FPS: {fps_epoch:.2f}\")\n        print(f\"GPU Memory Allocated: {gpu_allocated:.2f} GB, GPU Memory Reserved: {gpu_reserved:.2f} GB\")\n\n        # Validation Phase\n        model.eval()\n        val_loss, correct, total = 0.0, 0, 0\n        with torch.no_grad():\n            for images, labels in tqdm(val_loader, desc=\"Validation Batches\"):\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n\n                # Check for logits attribute\n                if hasattr(outputs, 'logits'):\n                    outputs = outputs.logits\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                total += labels.size(0)\n                correct += predicted.eq(labels).sum().item()\n\n        val_epoch_loss = val_loss / len(val_loader)\n        val_epoch_acc = 100. * correct / total\n        val_losses.append(val_epoch_loss)  # Track validation loss\n        val_accuracies.append(val_epoch_acc)  # Track validation accuracy\n        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2f}%\")\n\n        # Step the LR scheduler\n        scheduler.step(val_epoch_loss)\n\n        # Early Stopping Check\n        early_stopping(val_epoch_loss)\n        if early_stopping.early_stop:\n            print(\"Stopping early due to convergence.\")\n            break\n\n    # Plot Results\n    plot_results(train_losses, val_losses, train_accuracies, val_accuracies, learning_rates, fps, gpu_usage)\n\n\ndef plot_results(train_losses, val_losses, train_accuracies, val_accuracies, learning_rates, fps, gpu_usage):\n    # Learning Rate\n    plt.figure(figsize=(8, 6))\n    plt.plot(range(1, len(learning_rates) + 1), learning_rates, marker='o')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Learning Rate\")\n    plt.title(\"Learning Rate Schedule\")\n    plt.grid()\n    plt.show()\n\n    # Training vs Validation Accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label=\"Training Accuracy\", marker='o')\n    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(\"Training vs Validation Accuracy\")\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n    # FPS\n    plt.figure(figsize=(8, 6))\n    plt.plot(range(1, len(fps) + 1), fps, marker='o')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Frames Per Second (FPS)\")\n    plt.title(\"Training Speed (FPS)\")\n    plt.grid()\n    plt.show()\n\n    # GPU Usage\n    allocated, reserved = zip(*gpu_usage)\n    plt.figure(figsize=(8, 6))\n    plt.plot(range(len(allocated)), allocated, label=\"GPU Allocated (GB)\")\n    plt.plot(range(len(reserved)), reserved, label=\"GPU Reserved (GB)\")\n    plt.xlabel(\"Batches\")\n    plt.ylabel(\"GPU Memory (GB)\")\n    plt.title(\"GPU Memory Usage\")\n    plt.legend()\n    plt.grid()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:39.591192Z","iopub.execute_input":"2024-12-23T12:30:39.591381Z","iopub.status.idle":"2024-12-23T12:30:39.609822Z","shell.execute_reply.started":"2024-12-23T12:30:39.591357Z","shell.execute_reply":"2024-12-23T12:30:39.609260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = train_and_evaluate(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    criterion=criterion,\n    device=device,\n    patience=5,  \n    num_epochs=50\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T12:30:39.610561Z","iopub.execute_input":"2024-12-23T12:30:39.610741Z","iopub.status.idle":"2024-12-23T15:00:43.603309Z","shell.execute_reply.started":"2024-12-23T12:30:39.610726Z","shell.execute_reply":"2024-12-23T15:00:43.602568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"def evaluate_model_with_metrics(model, loader, binary_classification=True):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []  \n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to('cuda'), labels.to('cuda')\n            \n            # Get model outputs\n            outputs = model(images)\n            \n            # For DeiT models, extract logits\n            if hasattr(outputs, 'logits'):  \n                outputs = outputs.logits\n            \n            # Get predicted classes\n            _, predicted = outputs.max(1)\n\n            # Accumulate metrics\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n            # Probabilities for ROC AUC\n            if binary_classification:\n                probabilities = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n                all_probs.extend(probabilities)\n\n    # Accuracy\n    accuracy = 100. * correct / total\n    print(f\"Accuracy on test set: {accuracy:.2f}%\")\n\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n\n    # Confusion Matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    print(\"Confusion Matrix:\\n\", cm)\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(all_labels),\n                yticklabels=np.unique(all_labels), cbar=False)\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Precision, Recall, F1-Score\n    precision = precision_score(all_labels, all_preds, average='binary' if binary_classification else 'weighted')\n    recall = recall_score(all_labels, all_preds, average='binary' if binary_classification else 'weighted')\n    f1 = f1_score(all_labels, all_preds, average='binary' if binary_classification else 'weighted')\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n\n    # AUC-ROC and ROC Curve (for binary classification)\n    if binary_classification:\n        all_probs = np.array(all_probs)\n        if len(np.unique(all_labels)) == 2: \n            fpr, tpr, _ = roc_curve(all_labels, all_probs)\n            auc_score = auc(fpr, tpr)\n            print(f\"AUC-ROC: {auc_score:.4f}\")\n\n            # Plot ROC Curve\n            plt.figure()\n            plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n            plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2)\n            plt.xlabel('False Positive Rate')\n            plt.ylabel('True Positive Rate')\n            plt.title('Receiver Operating Characteristic (ROC) Curve')\n            plt.legend(loc=\"lower right\")\n            plt.grid()\n            plt.show()\n        else:\n            print(\"AUC-ROC is not supported for multi-class tasks without modification.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:00:43.606285Z","iopub.execute_input":"2024-12-23T15:00:43.606538Z","iopub.status.idle":"2024-12-23T15:00:43.616966Z","shell.execute_reply.started":"2024-12-23T15:00:43.606514Z","shell.execute_reply":"2024-12-23T15:00:43.616241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model_with_metrics(model, test_loader, binary_classification=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:00:43.617933Z","iopub.execute_input":"2024-12-23T15:00:43.618233Z","iopub.status.idle":"2024-12-23T15:01:24.845535Z","shell.execute_reply.started":"2024-12-23T15:00:43.618202Z","shell.execute_reply":"2024-12-23T15:01:24.844672Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Save Model**","metadata":{}},{"cell_type":"code","source":"# File paths to save models\nresnet18_path_50epochs = '/kaggle/working/model.pth'\n\ntorch.save(model.state_dict(), resnet18_path_50epochs)\n\nprint(\"Models saved successfully to /kaggle/working/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:01:24.846581Z","iopub.execute_input":"2024-12-23T15:01:24.846828Z","iopub.status.idle":"2024-12-23T15:01:24.989342Z","shell.execute_reply.started":"2024-12-23T15:01:24.846805Z","shell.execute_reply":"2024-12-23T15:01:24.988612Z"}},"outputs":[],"execution_count":null}]}